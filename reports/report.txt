=== CATEGORY (baseline) ===
                  precision    recall  f1-score   support

      auth_issue      1.000     0.982     0.991        57
      data_issue      0.984     1.000     0.992        61
deployment_issue      1.000     1.000     1.000        63
         latency      1.000     0.938     0.968        65
          outage      0.944     1.000     0.971        68
   payment_issue      0.984     0.984     0.984        64

        accuracy                          0.984       378
       macro avg      0.985     0.984     0.985       378
    weighted avg      0.985     0.984     0.984       378

macro_f1=0.9845 weighted_f1=0.9841 acc=0.9841
Label distribution (train): auth_issue:228 (15.1%), data_issue:244 (16.2%), deployment_issue:249 (16.5%), latency:261 (17.3%), outage:271 (18.0%), payment_issue:255 (16.9%)
Label distribution (test):  auth_issue:57 (15.1%), data_issue:61 (16.1%), deployment_issue:63 (16.7%), latency:65 (17.2%), outage:68 (18.0%), payment_issue:64 (16.9%)

=== PRIORITY (baseline) ===
              precision    recall  f1-score   support

          P0      0.677     0.966     0.796        87
          P1      0.765     0.616     0.683       185
          P2      0.204     0.151     0.173        73
          P3      0.529     0.818     0.643        33

    accuracy                          0.624       378
   macro avg      0.544     0.638     0.574       378
weighted avg      0.616     0.624     0.607       378

macro_f1=0.5737 weighted_f1=0.6069 acc=0.6243 severe_mistake_rate=0.0159
p0_recall=0.9655 p0p1_recall=0.8640 p0p1_precision=0.8608
P0/P1 confusion matrix (binary): [[68, 38], [37, 235]]
Label distribution (train): P0:349 (23.1%), P1:738 (48.9%), P2:290 (19.2%), P3:131 (8.7%)
Label distribution (test):  P0:87 (23.0%), P1:185 (48.9%), P2:73 (19.3%), P3:33 (8.7%)
